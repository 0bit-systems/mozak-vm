#![allow(clippy::too_many_lines)]

use std::collections::HashMap;
use std::fmt::Display;

use anyhow::{ensure, Result};
use itertools::Itertools;
use log::Level::Debug;
use log::{debug, info, log_enabled};
use mozak_runner::elf::Program;
use mozak_runner::vm::ExecutionRecord;
use plonky2::field::extension::Extendable;
use plonky2::field::packable::Packable;
use plonky2::field::polynomial::{PolynomialCoeffs, PolynomialValues};
use plonky2::field::types::Field;
use plonky2::fri::batch_oracle::BatchFriOracle;
use plonky2::fri::oracle::PolynomialBatch;
use plonky2::fri::proof::FriProof;
use plonky2::fri::structure::{FriBatchInfo, FriInstanceInfo, FriOracleInfo};
use plonky2::hash::hash_types::RichField;
use plonky2::hash::merkle_tree::MerkleCap;
use plonky2::iop::challenger::Challenger;
use plonky2::plonk::config::GenericConfig;
use plonky2::timed;
use plonky2::util::log2_strict;
use plonky2::util::timing::TimingTree;
#[allow(clippy::wildcard_imports)]
use plonky2_maybe_rayon::*;
use starky::config::StarkConfig;
use starky::stark::{LookupConfig, Stark};

use super::mozak_stark::{MozakStark, TableKind, TableKindArray, TableKindSetBuilder};
use super::proof::{AllProof, BatchProof, StarkOpeningSet, StarkProof};
use crate::cross_table_lookup::ctl_utils::debug_ctl;
use crate::cross_table_lookup::{cross_table_lookup_data, CtlData};
use crate::generation::{debug_traces, generate_traces};
use crate::public_sub_table::public_sub_table_data_and_values;
use crate::stark::mozak_stark::{all_kind, all_starks, PublicInputs};
use crate::stark::permutation::challenge::GrandProductChallengeTrait;
use crate::stark::poly::compute_quotient_polys;

pub(crate) fn merge_fri_instances<F, const D: usize>(
    instances: &[&FriInstanceInfo<F, D>],
    polynomial_index_start: &mut [usize; 3],
) -> FriInstanceInfo<F, D>
where
    F: RichField + Extendable<D>, {
    assert!(!instances.is_empty());
    let base_instance = &instances[0];
    assert_eq!(base_instance.oracles.len(), 3);
    assert_eq!(base_instance.batches.len(), 3);

    let mut res = FriInstanceInfo {
        oracles: Vec::with_capacity(3),
        batches: Vec::with_capacity(3),
    };

    for i in 0..3 {
        res.oracles.push(FriOracleInfo {
            num_polys: 0,
            blinding: base_instance.oracles[i].blinding,
        });
        res.batches.push(FriBatchInfo {
            point: base_instance.batches[i].point,
            polynomials: vec![],
        });
    }

    for ins in instances {
        assert_eq!(ins.oracles.len(), 3);
        assert_eq!(ins.batches.len(), 3);

        for i in 0..3 {
            assert_eq!(res.oracles[i].blinding, ins.oracles[i].blinding);
            res.oracles[i].num_polys += ins.oracles[i].num_polys;

            assert_eq!(res.batches[i].point, ins.batches[i].point);
            for poly in ins.batches[i].polynomials.iter().cloned() {
                let mut poly = poly;
                poly.polynomial_index += polynomial_index_start[poly.oracle_index];
                // assert!(
                //     poly.polynomial_index < res.oracles[poly.oracle_index].num_polys,
                //     "{}, {}, ",
                //     poly.polynomial_index,
                //     res.oracles[poly.oracle_index].num_polys
                // );
                res.batches[i].polynomials.push(poly);
            }
        }

        for i in 0..3 {
            polynomial_index_start[i] += ins.oracles[i].num_polys;
        }
    }

    res
}

/// Prove the execution of a given [Program]
///
/// ## Parameters
/// `program`: A serialized ELF Program
/// `record`: Non-constrained execution trace generated by the runner
/// `mozak_stark`: Mozak-VM Gadgets
/// `config`: Stark and FRI security configurations
/// `public_inputs`: Public Inputs to the Circuit
/// `timing`: Profiling tool
pub fn prove<F, C, const D: usize>(
    program: &Program,
    record: &ExecutionRecord<F>,
    mozak_stark: &MozakStark<F, D>,
    config: &StarkConfig,
    public_inputs: PublicInputs<F>,
    timing: &mut TimingTree,
) -> Result<AllProof<F, C, D>>
where
    F: RichField + Extendable<D>,
    C: GenericConfig<D, F = F>, {
    debug!("Starting Prove");
    let traces_poly_values = generate_traces(program, record);
    if mozak_stark.debug || std::env::var("MOZAK_STARK_DEBUG").is_ok() {
        debug_traces(&traces_poly_values, mozak_stark, &public_inputs);
        debug_ctl(&traces_poly_values, mozak_stark);
    }
    prove_with_traces(
        mozak_stark,
        config,
        public_inputs,
        &traces_poly_values,
        timing,
    )
}

pub fn batch_prove<F, C, const D: usize>(
    program: &Program,
    record: &ExecutionRecord<F>,
    mozak_stark: &MozakStark<F, D>,
    config: &StarkConfig,
    public_inputs: PublicInputs<F>,
    timing: &mut TimingTree,
) -> Result<BatchProof<F, C, D>>
where
    F: RichField + Extendable<D>,
    C: GenericConfig<D, F = F>, {
    debug!("Starting Prove");
    let traces_poly_values = generate_traces(program, record);
    if mozak_stark.debug || std::env::var("MOZAK_STARK_DEBUG").is_ok() {
        debug_traces(&traces_poly_values, mozak_stark, &public_inputs);
        debug_ctl(&traces_poly_values, mozak_stark);
    }
    let rate_bits = config.fri_config.rate_bits;
    let cap_height = config.fri_config.cap_height;

    // We cannot batch prove these tables because trace caps are needed as public
    // inputs for the following tables.
    let public_table_kinds = vec![
        TableKind::Program,
        TableKind::ElfMemoryInit,
        TableKind::MozakMemoryInit,
    ];

    let mut degree_log_map: HashMap<usize, Vec<TableKind>> = HashMap::new();
    let mut batch_traces_poly_values = all_kind!(|kind| if public_table_kinds.contains(&kind) {
        None
    } else {
        degree_log_map
            .entry(log2_strict(traces_poly_values[kind][0].len()))
            .or_insert(Vec::new())
            .push(kind);
        Some(&traces_poly_values[kind])
    });

    let mut batch_trace_polys: Vec<_> = batch_traces_poly_values
        .iter()
        .filter_map(|t| *t)
        .flat_map(|v| v.clone())
        .collect();
    batch_trace_polys.sort_by(|a, b| b.len().cmp(&a.len()));
    let bacth_trace_polys_len = batch_trace_polys.len();

    let batch_trace_commitments: BatchFriOracle<F, C, D> = timed!(
        timing,
        "Compute trace commitments for batch tables",
        BatchFriOracle::from_values(
            batch_trace_polys,
            rate_bits,
            false,
            cap_height,
            timing,
            &vec![None; bacth_trace_polys_len],
        )
    );

    let trace_commitments = timed!(
        timing,
        "Compute trace commitments for each table",
        traces_poly_values
            .clone()
            .with_kind()
            .map(|(trace, table)| {
                timed!(
                    timing,
                    &format!("compute trace commitment for {table:?}"),
                    PolynomialBatch::<F, C, D>::from_values(
                        trace.clone(),
                        rate_bits,
                        false,
                        cap_height,
                        timing,
                        None,
                    )
                )
            })
    );

    // TODO: todo
    // let trace_caps = batch_trace_commitments.field_merkle_tree.cap;

    let trace_caps = trace_commitments
        .each_ref()
        .map(|c| c.merkle_tree.cap.clone());
    // Add trace commitments to the challenger entropy pool.
    let mut challenger = Challenger::<F, C::Hasher>::new();
    for cap in &trace_caps {
        challenger.observe_cap(cap);
    }

    let ctl_challenges = challenger.get_grand_product_challenge_set(config.num_challenges);
    let ctl_data_per_table = timed!(
        timing,
        "Compute CTL data for each table",
        cross_table_lookup_data::<F, D>(
            &traces_poly_values,
            &mozak_stark.cross_table_lookups,
            &ctl_challenges
        )
    );

    let (public_sub_table_data_per_table, public_sub_table_values) =
        public_sub_table_data_and_values::<F, D>(
            &traces_poly_values,
            &mozak_stark.public_sub_tables,
            &ctl_challenges,
        );

    let (proofs, batch_stark_proof) = batch_prove_with_commitments(
        mozak_stark,
        config,
        &public_table_kinds,
        &public_inputs,
        degree_log_map,
        &traces_poly_values,
        &trace_commitments,
        &batch_trace_commitments,
        &ctl_data_per_table,
        &public_sub_table_data_per_table,
        // todo: remove clone()
        &mut challenger.clone(),
        timing,
    )?;

    let program_rom_trace_cap = trace_caps[TableKind::Program].clone();
    let elf_memory_init_trace_cap = trace_caps[TableKind::ElfMemoryInit].clone();
    let mozak_memory_init_trace_cap = trace_caps[TableKind::MozakMemoryInit].clone();
    if log_enabled!(Debug) {
        timing.print();
    }
    Ok(BatchProof {
        proofs,
        program_rom_trace_cap,
        elf_memory_init_trace_cap,
        mozak_memory_init_trace_cap,
        public_inputs,
        public_sub_table_values,
        batch_stark_proof,
    })
}

/// Given the traces generated from [`generate_traces`], prove a [`MozakStark`].
///
/// # Errors
/// Errors if proving fails.
pub fn prove_with_traces<F, C, const D: usize>(
    mozak_stark: &MozakStark<F, D>,
    config: &StarkConfig,
    public_inputs: PublicInputs<F>,
    traces_poly_values: &TableKindArray<Vec<PolynomialValues<F>>>,
    timing: &mut TimingTree,
) -> Result<AllProof<F, C, D>>
where
    F: RichField + Extendable<D>,
    C: GenericConfig<D, F = F>, {
    let rate_bits = config.fri_config.rate_bits;
    let cap_height = config.fri_config.cap_height;

    // We cannot batch prove these tables because trace caps are needed as public
    // inputs for the following tables.
    let public_table_kinds = vec![
        TableKind::Program,
        TableKind::ElfMemoryInit,
        TableKind::MozakMemoryInit,
    ];

    // let separate_trace_commitments = timed!(
    //     timing,
    //     "Compute trace commitments for separate tables",
    //     all_kind!(|kind| if public_table_kinds.contains(&kind) {
    //         Some(PolynomialBatch::<F, C, D>::from_values(
    //             traces_poly_values[kind].clone(),
    //             rate_bits,
    //             false,
    //             cap_height,
    //             timing,
    //             None,
    //         ))
    //     } else {
    //         None
    //     })
    // );

    let mut degree_log_map: HashMap<usize, Vec<TableKind>> = HashMap::new();
    let mut batch_traces_poly_values = all_kind!(|kind| if public_table_kinds.contains(&kind) {
        None
    } else {
        degree_log_map
            .entry(log2_strict(traces_poly_values[kind][0].len()))
            .or_insert(Vec::new())
            .push(kind);
        Some(&traces_poly_values[kind])
    });
    // let degree_logs: Vec<usize> = batch_traces_poly_values
    //     .iter()
    //     .filter_map(|&t| t)
    //     .map(|t| t[0].len())
    //     .collect();
    // let mut degree_logs_sorted = degree_logs.clone();
    // degree_logs_sorted.sort();
    // degree_logs_sorted.dedup();
    // degree_logs_sorted.reverse();
    // let degree_to_index_lookup = vec![0;32];
    // degree_logs.iter().enumerate(|i, d| degree_to_index_lookup[i] = );

    let mut batch_trace_polys: Vec<_> = batch_traces_poly_values
        .iter()
        .filter_map(|t| *t)
        .flat_map(|v| v.clone())
        .collect();
    batch_trace_polys.sort_by(|a, b| b.len().cmp(&a.len()));
    let bacth_trace_polys_len = batch_trace_polys.len();

    let batch_trace_commitments: BatchFriOracle<F, C, D> = timed!(
        timing,
        "Compute trace commitments for batch tables",
        BatchFriOracle::from_values(
            batch_trace_polys,
            rate_bits,
            false,
            cap_height,
            timing,
            &vec![None; bacth_trace_polys_len],
        )
    );

    let trace_commitments = timed!(
        timing,
        "Compute trace commitments for each table",
        traces_poly_values
            .clone()
            .with_kind()
            .map(|(trace, table)| {
                timed!(
                    timing,
                    &format!("compute trace commitment for {table:?}"),
                    PolynomialBatch::<F, C, D>::from_values(
                        trace.clone(),
                        rate_bits,
                        false,
                        cap_height,
                        timing,
                        None,
                    )
                )
            })
    );

    // TODO: todo
    // let trace_caps = batch_trace_commitments.field_merkle_tree.cap;

    let trace_caps = trace_commitments
        .each_ref()
        .map(|c| c.merkle_tree.cap.clone());
    // Add trace commitments to the challenger entropy pool.
    let mut challenger = Challenger::<F, C::Hasher>::new();
    for cap in &trace_caps {
        challenger.observe_cap(cap);
    }

    let ctl_challenges = challenger.get_grand_product_challenge_set(config.num_challenges);
    let ctl_data_per_table = timed!(
        timing,
        "Compute CTL data for each table",
        cross_table_lookup_data::<F, D>(
            traces_poly_values,
            &mozak_stark.cross_table_lookups,
            &ctl_challenges
        )
    );

    let (public_sub_table_data_per_table, public_sub_table_values) =
        public_sub_table_data_and_values::<F, D>(
            traces_poly_values,
            &mozak_stark.public_sub_tables,
            &ctl_challenges,
        );

    let _ = batch_prove_with_commitments(
        mozak_stark,
        config,
        &public_table_kinds,
        &public_inputs,
        degree_log_map,
        traces_poly_values,
        &trace_commitments,
        &batch_trace_commitments,
        &ctl_data_per_table,
        &public_sub_table_data_per_table,
        // todo: remove clone()
        &mut challenger.clone(),
        timing,
    );

    let proofs = timed!(
        timing,
        "compute all proofs given commitments",
        prove_with_commitments(
            mozak_stark,
            config,
            &public_inputs,
            traces_poly_values,
            &trace_commitments,
            &ctl_data_per_table,
            &public_sub_table_data_per_table,
            &mut challenger,
            timing
        )?
    );

    let program_rom_trace_cap = trace_caps[TableKind::Program].clone();
    let elf_memory_init_trace_cap = trace_caps[TableKind::ElfMemoryInit].clone();
    let mozak_memory_init_trace_cap = trace_caps[TableKind::MozakMemoryInit].clone();
    if log_enabled!(Debug) {
        timing.print();
    }
    Ok(AllProof {
        proofs,
        program_rom_trace_cap,
        elf_memory_init_trace_cap,
        mozak_memory_init_trace_cap,
        public_inputs,
        public_sub_table_values,
    })
}

/// Compute proof for a single STARK table, with lookup data.
///
/// # Errors
/// Errors if FRI parameters are wrongly configured, or if
/// there are no z polys, or if our
/// opening points are in our subgroup `H`,
#[allow(clippy::too_many_arguments)]
pub(crate) fn prove_single_table<F, C, S, const D: usize>(
    stark: &S,
    config: &StarkConfig,
    trace_poly_values: &[PolynomialValues<F>],
    trace_commitment: &PolynomialBatch<F, C, D>,
    public_inputs: &[F],
    ctl_data: &CtlData<F>,
    public_sub_table_data: &CtlData<F>,
    challenger: &mut Challenger<F, C::Hasher>,
    timing: &mut TimingTree,
) -> Result<StarkProof<F, C, D>>
where
    F: RichField + Extendable<D>,
    C: GenericConfig<D, F = F>,
    S: Stark<F, D> + Display, {
    let degree = trace_poly_values[0].len();
    let degree_bits = log2_strict(degree);
    let fri_params = config.fri_params(degree_bits);
    let rate_bits = config.fri_config.rate_bits;
    let cap_height = config.fri_config.cap_height;
    assert!(
        fri_params.total_arities() <= degree_bits + rate_bits - cap_height,
        "FRI total reduction arity is too large.",
    );

    let z_poly_public_sub_table = public_sub_table_data.z_polys();

    // commit to both z poly of ctl and open public
    let z_polys = vec![ctl_data.z_polys(), z_poly_public_sub_table]
        .into_iter()
        .flatten()
        .collect_vec();
    // TODO(Matthias): make the code work with empty z_polys, too.
    assert!(!z_polys.is_empty(), "No CTL? {stark}");

    let ctl_zs_commitment = timed!(
        timing,
        format!("{stark}: compute Zs commitment").as_str(),
        PolynomialBatch::from_values(
            z_polys,
            rate_bits,
            false,
            config.fri_config.cap_height,
            timing,
            None,
        )
    );
    let ctl_zs_cap = ctl_zs_commitment.merkle_tree.cap.clone();
    challenger.observe_cap(&ctl_zs_cap);

    let alphas = challenger.get_n_challenges(config.num_challenges);
    let quotient_polys = timed!(
        timing,
        format!("{stark}: compute quotient polynomial").as_str(),
        compute_quotient_polys::<F, <F as Packable>::Packing, C, S, D>(
            stark,
            trace_commitment,
            &ctl_zs_commitment,
            public_inputs,
            ctl_data,
            public_sub_table_data,
            &alphas,
            degree_bits,
            config,
        )
    );

    let all_quotient_chunks = timed!(
        timing,
        format!("{stark}: split quotient polynomial").as_str(),
        quotient_polys
            .into_par_iter()
            .flat_map(|mut quotient_poly| {
                quotient_poly
                    .trim_to_len(degree * stark.quotient_degree_factor())
                    .expect(
                        "Quotient has failed, the vanishing polynomial is not divisible by Z_H",
                    );
                // Split quotient into degree-n chunks.
                quotient_poly.chunks(degree)
            })
            .collect()
    );
    let quotient_commitment = timed!(
        timing,
        format!("{stark}: compute quotient commitment").as_str(),
        PolynomialBatch::from_coeffs(
            all_quotient_chunks,
            rate_bits,
            false,
            config.fri_config.cap_height,
            timing,
            None,
        )
    );
    let quotient_polys_cap = quotient_commitment.merkle_tree.cap.clone();
    challenger.observe_cap(&quotient_polys_cap);

    let zeta = challenger.get_extension_challenge::<D>();
    // To avoid leaking witness data, we want to ensure that our opening locations,
    // `zeta` and `g * zeta`, are not in our subgroup `H`. It suffices to check
    // `zeta` only, since `(g * zeta)^n = zeta^n`, where `n` is the order of
    // `g`.
    let g = F::primitive_root_of_unity(degree_bits);
    ensure!(
        zeta.exp_power_of_2(degree_bits) != F::Extension::ONE,
        "Opening point is in the subgroup."
    );

    let openings = StarkOpeningSet::new(
        zeta,
        g,
        trace_commitment,
        &ctl_zs_commitment,
        &quotient_commitment,
        degree_bits,
    );

    challenger.observe_openings(&openings.to_fri_openings());

    let initial_merkle_trees = vec![trace_commitment, &ctl_zs_commitment, &quotient_commitment];

    // Make sure that we do not use Starky's lookups.
    assert!(!stark.requires_ctls());
    assert!(!stark.uses_lookups());
    let num_make_rows_public_data = public_sub_table_data.len();
    let fri_instance = &stark.fri_instance(
        zeta,
        g,
        0,
        vec![],
        config,
        Some(&LookupConfig {
            degree_bits,
            num_zs: ctl_data.len() + num_make_rows_public_data,
        }),
    );
    for i in 0..3 {
        assert_eq!(
            initial_merkle_trees[i].polynomials.len(),
            fri_instance.oracles[i].num_polys,
        );
    }

    info!(
        "{stark} ctl polys {}",
        initial_merkle_trees[1].polynomials.len()
    );
    let opening_proof = timed!(
        timing,
        format!("{stark}: compute opening proofs").as_str(),
        PolynomialBatch::prove_openings(
            fri_instance,
            &initial_merkle_trees,
            challenger,
            &fri_params,
            timing,
        )
    );

    Ok(StarkProof {
        trace_cap: trace_commitment.merkle_tree.cap.clone(),
        ctl_zs_cap,
        quotient_polys_cap,
        openings,
        opening_proof,
    })
}

/// Given the traces generated from [`generate_traces`] along with their
/// commitments, prove a [`MozakStark`].
///
/// # Errors
/// Errors if proving fails.
#[allow(clippy::too_many_arguments)]
pub fn prove_with_commitments<F, C, const D: usize>(
    mozak_stark: &MozakStark<F, D>,
    config: &StarkConfig,
    public_inputs: &PublicInputs<F>,
    traces_poly_values: &TableKindArray<Vec<PolynomialValues<F>>>,
    trace_commitments: &TableKindArray<PolynomialBatch<F, C, D>>,
    ctl_data_per_table: &TableKindArray<CtlData<F>>,
    public_sub_data_per_table: &TableKindArray<CtlData<F>>,
    challenger: &mut Challenger<F, C::Hasher>,
    timing: &mut TimingTree,
) -> Result<TableKindArray<StarkProof<F, C, D>>>
where
    F: RichField + Extendable<D>,
    C: GenericConfig<D, F = F>, {
    let cpu_stark = [public_inputs.entry_point];
    let public_inputs = TableKindSetBuilder::<&[_]> {
        cpu_stark: &cpu_stark,
        ..Default::default()
    }
    .build();

    Ok(all_starks!(mozak_stark, |stark, kind| {
        prove_single_table(
            stark,
            config,
            &traces_poly_values[kind],
            &trace_commitments[kind],
            public_inputs[kind],
            &ctl_data_per_table[kind],
            &public_sub_data_per_table[kind],
            challenger,
            timing,
        )?
    }))
}

/// Given the traces generated from [`generate_traces`] along with their
/// commitments, prove a [`MozakStark`].
///
/// # Errors
/// Errors if proving fails.
#[allow(clippy::too_many_arguments)]
pub fn batch_prove_with_commitments<F, C, const D: usize>(
    mozak_stark: &MozakStark<F, D>,
    config: &StarkConfig,
    public_table_kinds: &[TableKind],
    public_inputs: &PublicInputs<F>,
    degree_log_map: HashMap<usize, Vec<TableKind>>,
    traces_poly_values: &TableKindArray<Vec<PolynomialValues<F>>>,
    trace_commitments: &TableKindArray<PolynomialBatch<F, C, D>>,
    batch_trace_commitments: &BatchFriOracle<F, C, D>,
    // separate_trace_commitments: &TableKindArray<PolynomialBatch<F, C, D>>,
    ctl_data_per_table: &TableKindArray<CtlData<F>>,
    public_sub_data_per_table: &TableKindArray<CtlData<F>>,
    challenger: &mut Challenger<F, C::Hasher>,
    timing: &mut TimingTree,
) -> Result<(TableKindArray<StarkProof<F, C, D>>, StarkProof<F, C, D>)>
where
    F: RichField + Extendable<D>,
    C: GenericConfig<D, F = F>, {
    let rate_bits = config.fri_config.rate_bits;
    let cap_height = config.fri_config.cap_height;

    let cpu_stark = [public_inputs.entry_point];
    let public_inputs = TableKindSetBuilder::<&[_]> {
        cpu_stark: &cpu_stark,
        ..Default::default()
    }
    .build();

    let separate_proofs = all_starks!(mozak_stark, |stark, kind| if public_table_kinds
        .contains(&kind)
    {
        Some(prove_single_table(
            stark,
            config,
            &traces_poly_values[kind],
            &trace_commitments[kind],
            public_inputs[kind],
            &ctl_data_per_table[kind],
            &public_sub_data_per_table[kind],
            challenger,
            timing,
        )?)
    } else {
        None
    });

    let batch_ctl_z_polys = all_kind!(|kind| {
        if !public_table_kinds.contains(&kind) {
            Some({
                let degree = traces_poly_values[kind][0].len();
                let degree_bits = log2_strict(degree);
                let fri_params = config.fri_params(degree_bits);
                assert!(
                    fri_params.total_arities() <= degree_bits + rate_bits - cap_height,
                    "FRI total reduction arity is too large.",
                );

                let z_poly_public_sub_table = public_sub_data_per_table[kind].z_polys();

                let z_polys = vec![ctl_data_per_table[kind].z_polys(), z_poly_public_sub_table]
                    .into_iter()
                    .flatten()
                    .collect_vec();

                assert!(!z_polys.is_empty());

                info!(
                    "ctl_data_per_table len {}",
                    ctl_data_per_table[kind].zs_columns.len()
                );
                info!("z_poly len {}", z_polys.len());

                z_polys
            })
        } else {
            None
        }
    });

    // TODO: can we remove duplicates in the ctl polynomials?
    let mut batch_ctl_zs_polys: Vec<_> = batch_ctl_z_polys
        .iter()
        .filter_map(|t| t.as_ref())
        .flat_map(|v| v.iter().cloned())
        .collect();
    batch_ctl_zs_polys.sort_by(|a, b| b.len().cmp(&a.len()));
    let batch_ctl_zs_polys_len = batch_ctl_zs_polys.len();

    let batch_ctl_zs_commitments: BatchFriOracle<F, C, D> = timed!(
        timing,
        "compute batch Zs commitment",
        BatchFriOracle::from_values(
            batch_ctl_zs_polys,
            rate_bits,
            false,
            config.fri_config.cap_height,
            timing,
            &vec![None; batch_ctl_zs_polys_len],
        )
    );

    let ctl_zs_commitments = all_starks!(mozak_stark, |stark, kind| timed!(
        timing,
        format!("{stark}: compute Zs commitment").as_str(),
        if let Some(poly) = &batch_ctl_z_polys[kind] {
            Some(PolynomialBatch::<F, C, D>::from_values(
                poly.clone(),
                rate_bits,
                false,
                config.fri_config.cap_height,
                timing,
                None,
            ))
        } else {
            None
        }
    ));

    let ctl_zs_cap = batch_ctl_zs_commitments.field_merkle_tree.cap.clone();
    challenger.observe_cap(&ctl_zs_cap);

    let alphas = challenger.get_n_challenges(config.num_challenges);

    // TODO: we should be able to compute `quotient_polys` from
    // `batch_trace_commitments` and `batch_ctl_zs_commitments`.
    let quotient_chunks = all_starks!(mozak_stark, |stark, kind| {
        if let Some(ctl_zs_commitment) = ctl_zs_commitments[kind].as_ref() {
            let degree = traces_poly_values[kind][0].len();
            let degree_bits = log2_strict(degree);
            let quotient_polys = timed!(
                timing,
                format!("{stark}: compute quotient polynomial").as_str(),
                compute_quotient_polys::<F, <F as Packable>::Packing, C, _, D>(
                    stark,
                    &trace_commitments[kind],
                    &ctl_zs_commitment,
                    public_inputs[kind],
                    &ctl_data_per_table[kind],
                    &public_sub_data_per_table[kind],
                    &alphas,
                    degree_bits,
                    config,
                )
            );
            assert!(!quotient_polys.is_empty());

            let quotient_chunks: Vec<PolynomialCoeffs<F>> = timed!(
                timing,
                format!("{stark}: split quotient polynomial").as_str(),
                quotient_polys
                    .into_par_iter()
                    .flat_map(|mut quotient_poly| {
                        quotient_poly
                    .trim_to_len(degree * stark.quotient_degree_factor())
                    .expect(
                        "Quotient has failed, the vanishing polynomial is not divisible by Z_H",
                    );
                        // Split quotient into degree-n chunks.
                        quotient_poly.chunks(degree)
                    })
                    .collect()
            );
            Some(quotient_chunks)
        } else {
            None
        }
    });

    let mut batch_quotient_chunks: Vec<_> = quotient_chunks
        .iter()
        .filter_map(|t| t.as_ref())
        .flat_map(|v| v.iter().cloned())
        .collect();
    batch_quotient_chunks.sort_by(|a, b| b.len().cmp(&a.len()));
    let batch_quotient_chunks_len = batch_quotient_chunks.len();

    let quotient_commitments = all_starks!(mozak_stark, |stark, kind| timed!(
        timing,
        format!("{stark}: compute quotient commitment").as_str(),
        if let Some(poly) = &quotient_chunks[kind] {
            Some(PolynomialBatch::<F, C, D>::from_coeffs(
                poly.clone(),
                rate_bits,
                false,
                config.fri_config.cap_height,
                timing,
                None,
            ))
        } else {
            None
        }
    ));

    let batch_quotient_commitments: BatchFriOracle<F, C, D> = timed!(
        timing,
        "compute batch Zs commitment",
        BatchFriOracle::from_coeffs(
            batch_quotient_chunks,
            rate_bits,
            false,
            config.fri_config.cap_height,
            timing,
            &vec![None; batch_quotient_chunks_len],
        )
    );

    let quotient_polys_cap = batch_quotient_commitments.field_merkle_tree.cap.clone();
    challenger.observe_cap(&quotient_polys_cap);

    let zeta = challenger.get_extension_challenge::<D>();

    // TODO: compute `openings` from `batch_trace_commitments` and
    // `batch_ctl_zs_commitments`.
    let batch_openings = all_starks!(mozak_stark, |stark, kind| if let Some(ctl_zs_commitment) =
        ctl_zs_commitments[kind].as_ref()
    {
        if let Some(quotient_commitment) = quotient_commitments[kind].as_ref() {
            let degree = traces_poly_values[kind][0].len();
            let degree_bits = log2_strict(degree);
            // To avoid leaking witness data, we want to ensure that our opening locations,
            // `zeta` and `g * zeta`, are not in our subgroup `H`. It suffices to check
            // `zeta` only, since `(g * zeta)^n = zeta^n`, where `n` is the order of
            // `g`.
            let g = F::primitive_root_of_unity(degree_bits);
            ensure!(
                zeta.exp_power_of_2(degree_bits) != F::Extension::ONE,
                "Opening point is in the subgroup."
            );
            let openings = StarkOpeningSet::new(
                zeta,
                g,
                &trace_commitments[kind],
                &ctl_zs_commitment,
                &quotient_commitment,
                degree_bits,
            );

            challenger.observe_openings(&openings.to_fri_openings());
            Some(openings)
        } else {
            None
        }
    } else {
        None
    });

    let fri_instances = all_starks!(mozak_stark, |stark, kind| if !public_table_kinds
        .contains(&kind)
    {
        Some({
            let degree = traces_poly_values[kind][0].len();
            let degree_bits = log2_strict(degree);
            let g = F::primitive_root_of_unity(degree_bits);

            stark.fri_instance(
                zeta,
                g,
                0,
                vec![],
                config,
                Some(&LookupConfig {
                    degree_bits,
                    num_zs: ctl_data_per_table[kind].len() + public_sub_data_per_table[kind].len(),
                }),
            )
        })
    } else {
        None
    });

    // Merge FRI instances by its polynomial degree
    let mut degree_bits: Vec<usize> = degree_log_map.keys().cloned().collect();
    degree_bits.sort();
    degree_bits.reverse();

    let fri_instance_groups = degree_bits
        .iter()
        .map(|degree_log| {
            degree_log_map[degree_log]
                .iter()
                .filter_map(|kind| fri_instances[*kind].as_ref())
                .collect::<Vec<_>>()
        })
        .collect::<Vec<_>>();

    let mut polynomial_index_start = [0, 0, 0];
    let batch_fri_instances = fri_instance_groups
        .iter()
        .map(|ins| merge_fri_instances(ins, &mut polynomial_index_start))
        .collect::<Vec<_>>();

    let initial_merkle_trees = vec![
        batch_trace_commitments,
        &batch_ctl_zs_commitments,
        &batch_quotient_commitments,
    ];

    for i in 0..3 {
        assert_eq!(
            initial_merkle_trees[i].polynomials.len(),
            batch_fri_instances
                .iter()
                .map(|ins| ins.oracles[i].num_polys)
                .collect::<Vec<usize>>()
                .iter()
                .sum::<usize>(),
        );
    }

    let mut fri_params = config.fri_params(degree_bits[0]);
    fri_params.reduction_arity_bits =
        batch_reduction_arity_bits(degree_bits, rate_bits, cap_height);
    let _opening_proof = timed!(
        timing,
        format!("compute batch opening proofs").as_str(),
        BatchFriOracle::prove_openings(
            &batch_fri_instances,
            &initial_merkle_trees,
            challenger,
            &fri_params,
            timing,
        )
    );

    let empty_fri_proof = FriProof {
        commit_phase_merkle_caps: vec![],
        query_round_proofs: vec![],
        final_poly: PolynomialCoeffs { coeffs: vec![] },
        pow_witness: F::ZERO,
    };
    let empty_opening_set = StarkOpeningSet {
        local_values: vec![],
        next_values: vec![],
        ctl_zs: vec![],
        ctl_zs_next: vec![],
        ctl_zs_last: vec![],
        quotient_polys: vec![],
    };
    Ok((
        all_kind!(|kind| {
            if public_table_kinds.contains(&kind) {
                <Option<StarkProof<F, C, D>> as Clone>::clone(&separate_proofs[kind])
                    .expect("No Proof")
            } else {
                StarkProof {
                    trace_cap: MerkleCap::default(),
                    ctl_zs_cap: MerkleCap::default(),
                    quotient_polys_cap: MerkleCap::default(),
                    openings: <Option<StarkOpeningSet<F, D>> as Clone>::clone(
                        &batch_openings[kind],
                    )
                    .expect("No Openings"),
                    opening_proof: empty_fri_proof.clone(),
                }
            }
        }),
        StarkProof {
            trace_cap: batch_trace_commitments.field_merkle_tree.cap.clone(),
            ctl_zs_cap,
            quotient_polys_cap,
            openings: empty_opening_set,
            opening_proof: empty_fri_proof.clone(),
        },
    ))
}

// TODO: find a better place for this function
fn batch_reduction_arity_bits(
    degree_bits: Vec<usize>,
    rate_bits: usize,
    cap_height: usize,
) -> Vec<usize> {
    let mut result = Vec::new();
    let arity_bits = 3;
    let mut cur_index = 0;
    let mut cur_degree_bits = degree_bits[cur_index];
    while cur_degree_bits + rate_bits >= cap_height + arity_bits {
        let mut cur_arity_bits = arity_bits;
        let target_degree_bits = cur_degree_bits - arity_bits;
        if cur_index < degree_bits.len() - 1 && target_degree_bits < degree_bits[cur_index + 1] {
            cur_arity_bits = cur_degree_bits - degree_bits[cur_index + 1];
            cur_index += 1;
        }
        result.push(cur_arity_bits);
        cur_degree_bits -= cur_arity_bits;
        assert!(cur_degree_bits >= 0);
    }
    result
}

#[cfg(test)]
mod tests {

    use mozak_runner::code;
    use mozak_runner::instruction::{Args, Instruction, Op};
    use plonky2::field::goldilocks_field::GoldilocksField;
    use plonky2::field::types::Field;
    use plonky2::hash::poseidon2::Poseidon2Hash;
    use plonky2::plonk::config::{GenericConfig, GenericHashOut, Hasher, PoseidonGoldilocksConfig};
    use plonky2::util::timing::TimingTree;

    use crate::stark::mozak_stark::{MozakStark, PublicInputs};
    use crate::stark::proof::{AllProof, BatchProof};
    use crate::stark::prover::{batch_prove, prove};
    use crate::stark::verifier::verify_proof;
    use crate::test_utils::{
        create_poseidon2_test, fast_test_config, Poseidon2Test, ProveAndVerify,
    };
    use crate::utils::from_u32;

    #[test]
    fn batch_prove_add() {
        let (program, record) = code::execute(
            [Instruction {
                op: Op::ADD,
                args: Args {
                    rd: 5,
                    rs1: 6,
                    rs2: 7,
                    ..Args::default()
                },
            }],
            &[],
            &[(6, 3), (7, 4)],
        );
        let config = fast_test_config();

        const D: usize = 2;
        type C = PoseidonGoldilocksConfig;
        type F = <C as GenericConfig<D>>::F;

        let stark: MozakStark<F, D> = MozakStark::default();
        let public_inputs = PublicInputs {
            entry_point: from_u32(program.entry_point),
        };

        let all_proof: BatchProof<F, C, D> = batch_prove(
            &program,
            &record,
            &stark,
            &config,
            public_inputs,
            &mut TimingTree::default(),
        )
        .unwrap();
        // verify_proof(&stark, all_proof, &config).unwrap();
    }

    #[test]
    fn prove_halt() {
        let (program, record) = code::execute([], &[], &[]);
        MozakStark::prove_and_verify(&program, &record).unwrap();
    }

    #[test]
    fn prove_lui() {
        let lui = Instruction {
            op: Op::ADD,
            args: Args {
                rd: 1,
                imm: 0x8000_0000,
                ..Args::default()
            },
        };
        let (program, record) = code::execute([lui], &[], &[]);
        assert_eq!(record.last_state.get_register_value(1), 0x8000_0000);
        MozakStark::prove_and_verify(&program, &record).unwrap();
    }

    #[test]
    fn prove_lui_2() {
        let (program, record) = code::execute(
            [Instruction {
                op: Op::ADD,
                args: Args {
                    rd: 1,
                    imm: 0xDEAD_BEEF,
                    ..Args::default()
                },
            }],
            &[],
            &[],
        );
        assert_eq!(record.last_state.get_register_value(1), 0xDEAD_BEEF,);
        MozakStark::prove_and_verify(&program, &record).unwrap();
    }

    #[test]
    fn prove_beq() {
        let (program, record) = code::execute(
            [Instruction {
                op: Op::BEQ,
                args: Args {
                    rs1: 0,
                    rs2: 1,
                    imm: 42, // branch target
                    ..Args::default()
                },
            }],
            &[],
            &[(1, 2)],
        );
        assert_eq!(record.last_state.get_pc(), 8);
        MozakStark::prove_and_verify(&program, &record).unwrap();
    }

    fn test_poseidon2(test_data: &[Poseidon2Test]) {
        let (program, record) = create_poseidon2_test(test_data);
        for test_datum in test_data {
            let output: Vec<u8> = (0..32_u8)
                .map(|i| {
                    record
                        .last_state
                        .load_u8(test_datum.output_start_addr + u32::from(i))
                })
                .collect();
            let mut data_bytes = test_datum.data.as_bytes().to_vec();
            // VM expects input len to be multiple of RATE bits
            data_bytes.resize(data_bytes.len().next_multiple_of(8), 0_u8);
            let data_fields: Vec<GoldilocksField> = data_bytes
                .iter()
                .map(|x| GoldilocksField::from_canonical_u8(*x))
                .collect();
            assert_eq!(output, Poseidon2Hash::hash_no_pad(&data_fields).to_bytes());
        }
        MozakStark::prove_and_verify(&program, &record).unwrap();
    }

    #[test]
    fn prove_poseidon2() {
        test_poseidon2(&[Poseidon2Test {
            data: "💥 Mozak-VM Rocks With Poseidon2".to_string(),
            input_start_addr: 1024,
            output_start_addr: 2048,
        }]);
        test_poseidon2(&[Poseidon2Test {
            data: "😇 Mozak is knowledge arguments based technology".to_string(),
            input_start_addr: 1024,
            output_start_addr: 2048,
        }]);
        test_poseidon2(&[
            Poseidon2Test {
                data: "💥 Mozak-VM Rocks With Poseidon2".to_string(),
                input_start_addr: 512,
                output_start_addr: 1024,
            },
            Poseidon2Test {
                data: "😇 Mozak is knowledge arguments based technology".to_string(),
                input_start_addr: 1024 + 32,
                // make sure input and output do not overlap with
                // earlier call
                output_start_addr: 2048,
            },
        ]);
    }
}
